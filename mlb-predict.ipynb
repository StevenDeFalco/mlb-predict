{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dd8593b",
   "metadata": {},
   "source": [
    "# MLB-Predict\n",
    "\n",
    "### In this notebook, I will...\n",
    "* import code from data.py\n",
    "* instantiate an intances of my class \n",
    "* collect a range of historical game data from that team\n",
    "* save the historical data to an .xlsx file\n",
    "* load the historical data into this notebook\n",
    "* prepare the data for training (i.e. strip unnecessary features)\n",
    "* divide data into testing and training sets\n",
    "* build a deep learning model using the keras library\n",
    "* train the model with my data and tune hyperparameters (save model weights)\n",
    "* graph performance of the model on training set\n",
    "* graph performance of the model on testing set\n",
    "* make predictions!\n",
    "\n",
    "#### *Note for viewers*\n",
    "There are some lines which I commented out and then re-executed as to remove large chunks of non-hideable code for when viewing on github.com. These are all noted, but generally occur during training of the model (hides excessive prints of training status during each iteration) and when collecting data (hides per game print statement indicating successful collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecb226f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from data import LeagueStats, TeamStats\n",
    "\n",
    "mlb = LeagueStats()\n",
    "\n",
    "nym = TeamStats(\"New York Mets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba27f4f",
   "metadata": {},
   "source": [
    "## Mets 2017-2023 Data retrieval\n",
    "This is where I fetch the data that I will use to train my \"mets-specific\" model: only uses Mets games. \n",
    "\n",
    "Get data from each season individually as to avoid lengthy pieces of uninterrupted code execution that is vulnerable to crashing due to API request timeouts and other misc. errors. \n",
    "\n",
    "#### *Note*\n",
    "Commented out and re-executed to remove large chunks of non-hideable code for when viewing on github.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c58ca19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nym_2017 = NYM.get_data(start_date=\"01/01/2017\", end_date=\"12/31/2017\", file_path=\"data/mets/seasons/2017.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c19d099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nym_2018 = NYM.get_data(start_date=\"01/01/2018\", end_date=\"12/31/2018\", file_path=\"data/mets/seasons/2018.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "124584e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nym_2019 = NYM.get_data(start_date=\"01/01/2019\", end_date=\"12/31/2019\", file_path=\"data/mets/seasons/2019.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "517705d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nym_2020 = NYM.get_data(start_date=\"01/01/2020\", end_date=\"12/31/2020\", file_path=\"data/mets/seasons/2020.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b71215d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nym_2021= NYM.get_data(start_date=\"01/01/2021\", end_date=\"12/31/2021\", file_path=\"data/mets/seasons/2021.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9d2354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nym_2022 = NYM.get_data(start_date=\"01/01/2022\", end_date=\"12/31/2022\", file_path=\"data/mets/seasons/2022.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27fb974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nym_2023 = NYM.get_data(start_date=\"01/01/2023\", end_date=\"07/01/2023\", file_path=\"data/mets/seasons/2023.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872b20bb",
   "metadata": {},
   "source": [
    "## MLB 2023 Season Data retrieval\n",
    "\n",
    "This is where I fetch the data that I will use to train my \"2023-season-specific\" model: uses all MLB games from 2023 season (up-to cutoff)\n",
    "\n",
    "#### *Note*\n",
    "Commented out and re-executed to remove large chunks of non-hideable code for when viewing on github.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68c2136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlb.get_data(start_date=\"04/01/2023\", end_date=\"04/15/2023\", file_path=\"data/seasons/2023/april_1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "304c9334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlb.get_data(start_date=\"04/15/2023\", end_date=\"04/30/2023\", file_path=\"data/seasons/2023/april_2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b163a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlb.get_data(start_date=\"05/01/2023\", end_date=\"05/15/2023\", file_path=\"data/seasons/2023/may_1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adf93983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlb.get_data(start_date=\"05/15/2023\", end_date=\"05/31/2023\", file_path=\"data/seasons/2023/may_2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98aa5609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlb.get_data(start_date=\"06/01/2023\", end_date=\"06/15/2023\", file_path=\"data/seasons/2023/june_1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b89e6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlb.get_data(start_date=\"06/15/2023\", end_date=\"06/30/2023\", file_path=\"data/seasons/2023/june_2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc378ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlb.get_data(start_date=\"07/01/2023\", end_date=\"07/09/2023\", file_path=\"data/seasons/2023/july_1.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88373b25",
   "metadata": {},
   "source": [
    "## Merging and loading data\n",
    "Load and merge season data from each xlsx file into a single xlsx file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf14d76",
   "metadata": {},
   "source": [
    "***Mets***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2a8e3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# path to the individual mets seasons data sheets\n",
    "mets_directory = 'data/mets/seasons'\n",
    "\n",
    "mets_data = pd.DataFrame()\n",
    "\n",
    "# iterate through mets data directory to retrieve each file\n",
    "for filename in os.listdir(mets_directory):\n",
    "    if filename.endswith('.xlsx'):\n",
    "        path = os.path.join(mets_directory, filename)\n",
    "        df = pd.read_excel(path)\n",
    "        mets_data = pd.concat([mets_data, df], ignore_index=True)\n",
    "        \n",
    "# save the merged data to a new xlsx file\n",
    "mets_data.to_excel('data/mets/2017-2023.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b800f01a",
   "metadata": {},
   "source": [
    "***MLB***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1b6ecdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# path to individual month data sheets in 2023 season\n",
    "mlb_directory = 'data/seasons/2023'\n",
    "\n",
    "mlb_data = pd.DataFrame()\n",
    "\n",
    "# iterate through mlb data directory to retrieve each file\n",
    "for filename in os.listdir(mlb_directory):\n",
    "    if filename.endswith('.xlsx'):\n",
    "        path = os.path.join(mlb_directory, filename)\n",
    "        df = pd.read_excel(path)\n",
    "        mlb_data = pd.concat([mlb_data, df], ignore_index=True)\n",
    "        \n",
    "mlb_data.to_excel('data/seasons/2023.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4072f27",
   "metadata": {},
   "source": [
    "#### *Loading and processing data* \n",
    "Load data from the master .xlsx file into a data frame. Prepare data for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53650265",
   "metadata": {},
   "source": [
    "***Mets***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9201e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "mets_data = pd.read_excel('data/mets/2017-2023.xlsx')\n",
    "\n",
    "# remove the game-id, date, home/away team features\n",
    "mets_data.drop(columns=['game-id', 'date', 'home-team', 'away-team'], inplace=True)\n",
    "\n",
    "# drops rows with missing labels\n",
    "mets_data = mets_data.dropna(subset=['did-home-win'])\n",
    "\n",
    "# convert 'did-home-win' labels to binary values\n",
    "mets_data['did-home-win'] = mets_data['did-home-win'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caa2728",
   "metadata": {},
   "source": [
    "***MLB***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93c6c41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb_data = pd.read_excel('data/seasons/2023.xlsx')\n",
    "\n",
    "# remove the game-id, date, home/away team features\n",
    "mlb_data.drop(columns=['game-id', 'date', 'home-team', 'away-team'], inplace=True)\n",
    "\n",
    "# drops rows with missing labels\n",
    "mlb_data = mlb_data.dropna(subset=['did-home-win'])\n",
    "\n",
    "# convert 'did-home-win' labels to binary values\n",
    "mlb_data['did-home-win'] = mlb_data['did-home-win'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d59e2be",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "#### *Experminetal Optimization*\n",
    "Rearrange the order of the features to attempt to optimize the model\n",
    "\n",
    "* Order 1: Place most important features first with each home team statistic immediately followed by the away's counter part. Allows for many meaningful comparisons between adjacent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daa5d5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "order1 = ['did-home-win',\n",
    "          'home-win-percentage', 'away-win-percentage',\n",
    "          'home-starter-season-era', 'away-starter-season-era',\n",
    "          'home-elo-probability', 'away-elo-probability', \n",
    "          'home-rating-probability', 'away-rating-probability',\n",
    "          'home-starter-season-win-percentage', 'away-starter-season-win-percentage',\n",
    "          'home-last10-avg-runs', 'away-last10-avg-runs',\n",
    "          'home-last10-avg-ops', 'away-last10-avg-ops',\n",
    "          'home-last10-avg-runs-allowed', 'away-last10-avg-runs-allowed', \n",
    "          'home-starter-season-avg', 'away-starter-season-avg',\n",
    "          'home-elo-pregame', 'away-elo-pregame',\n",
    "          'home-pitcher-rgs', 'away-pitcher-rgs',\n",
    "          'home-last10-avg-hits', 'away-last10-avg-hits',\n",
    "          'home-last10-avg-hits-allowed', 'away-last10-avg-hits-allowed',\n",
    "          'home-last10-avg-obp', 'away-last10-avg-obp',\n",
    "          'home-rating-pregame', 'away-rating-pregame',\n",
    "          'home-starter-season-runs-per9', 'away-starter-season-runs-per9',\n",
    "          'home-last10-avg-strikeouts', 'away-last10-avg-strikeouts',\n",
    "          'home-starter-career-era', 'away-starter-career-era']\n",
    "\n",
    "order2 = ['did-home-win',\n",
    "          'home-win-percentage', 'home-starter-season-era', \n",
    "          'home-elo-probability', 'home-rating-probability', \n",
    "          'home-starter-season-win-percentage', 'home-last10-avg-runs', \n",
    "          'home-last10-avg-ops', 'home-last10-avg-runs-allowed', \n",
    "          'home-starter-season-avg', 'home-elo-pregame', \n",
    "          'home-pitcher-rgs', 'home-last10-avg-hits', \n",
    "          'home-last10-avg-hits-allowed', 'home-last10-avg-obp', \n",
    "          'home-rating-pregame', 'home-starter-season-runs-per9', \n",
    "          'home-last10-avg-strikeouts', 'home-starter-career-era', \n",
    "          'away-win-percentage', 'away-starter-season-era', \n",
    "          'away-elo-probability', 'away-rating-probability',\n",
    "          'away-starter-season-win-percentage', 'away-last10-avg-runs',\n",
    "          'away-last10-avg-ops','away-last10-avg-runs-allowed', \n",
    "          'away-starter-season-avg', 'away-elo-pregame',\n",
    "          'away-pitcher-rgs', 'away-last10-avg-hits',\n",
    "          'away-last10-avg-hits-allowed', 'away-last10-avg-obp',\n",
    "          'away-rating-pregame', 'away-starter-season-runs-per9',\n",
    "          'away-last10-avg-strikeouts', 'away-starter-career-era']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5c9130",
   "metadata": {},
   "source": [
    "***Mets***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdb8a42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder the columns\n",
    "mets_data = mets_data[order1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4e7e07",
   "metadata": {},
   "source": [
    "***MLB***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73b98948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder the columns\n",
    "mlb_data = mlb_data[order1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1964ee8b",
   "metadata": {},
   "source": [
    "#### *Drop rows with missing labels*\n",
    "Drops all rows that are missing more than THRESHOLD features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d52b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant representing the amount of features that must missing for a row to be excluded/removed\n",
    "THRESHOLD = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6a24ef",
   "metadata": {},
   "source": [
    "***Mets***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b182503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops rows with too many missing features\n",
    "mets_data = mets_data.dropna(thresh=df.shape[1] - THRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a6f534",
   "metadata": {},
   "source": [
    "***MLB***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bf3c08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops rows with too many missing features\n",
    "mlb_data = mlb_data.dropna(thresh=df.shape[1] - THRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb71357",
   "metadata": {},
   "source": [
    "#### *Min-Max Feature Normalization*\n",
    "Normalize the numeric features to a scale of [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a2eaadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mets_scaler = MinMaxScaler()\n",
    "mlb_scaler  = MinMaxScaler()\n",
    "\n",
    "# scale all columns that don't represent averages between 0-1 (i.e. batting avg doesn't need scaling)\n",
    "columns_to_scale = ['home-starter-season-era', 'away-starter-season-era',\n",
    "                   'home-last10-avg-runs', 'away-last10-avg-runs',\n",
    "                   'home-last10-avg-runs-allowed', 'away-last10-avg-runs-allowed', \n",
    "                   'home-elo-pregame', 'away-elo-pregame',\n",
    "                   'home-pitcher-rgs', 'away-pitcher-rgs',\n",
    "                   'home-last10-avg-hits', 'away-last10-avg-hits',\n",
    "                   'home-last10-avg-hits-allowed', 'away-last10-avg-hits-allowed',\n",
    "                   'home-rating-pregame', 'away-rating-pregame',\n",
    "                   'home-starter-season-runs-per9', 'away-starter-season-runs-per9',\n",
    "                   'home-last10-avg-strikeouts', 'away-last10-avg-strikeouts',\n",
    "                   'home-starter-career-era', 'away-starter-career-era']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cc6a18",
   "metadata": {},
   "source": [
    "***Mets***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10f84109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# apply min-max normalization to selected features\n",
    "mets_data[columns_to_scale] = mets_scaler.fit_transform(mets_data[columns_to_scale])\n",
    "\n",
    "scaler_path = 'models/scalers/'\n",
    "with open(scaler_path + 'mets6year_scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(mets_scaler, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8426bf8f",
   "metadata": {},
   "source": [
    "***MLB***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "874e4788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# apply min-max normalization to selected features\n",
    "mlb_data[columns_to_scale] = mlb_scaler.fit_transform(mlb_data[columns_to_scale])\n",
    "\n",
    "scaler_path = 'models/scalers/'\n",
    "with open(scaler_path + 'mlb2023_scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(mlb_scaler, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d63a828",
   "metadata": {},
   "source": [
    "#### *Randomize data order, Split training and testing data*\n",
    "Ensures that training and testing data aren't chronologically grouped. Thus, will treat each game more independently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e1037d",
   "metadata": {},
   "source": [
    "***Mets***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee7f90f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mets features shape:  (899, 36)\n",
      "Mets labels shape:  (899,)\n",
      "Mets training set shape:  (764, 36) (764,)\n",
      "Mets testing set shape:  (135, 36) (135,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# randomize the order of the rows in the dataframe\n",
    "mets_data = mets_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# separate labels from the features\n",
    "mets_features = mets_data.drop('did-home-win', axis=1).values\n",
    "mets_labels = mets_data['did-home-win'].values\n",
    "\n",
    "# verify shapes features and labels\n",
    "print(\"Mets features shape: \", mets_features.shape)\n",
    "print(\"Mets labels shape: \", mets_labels.shape)\n",
    "\n",
    "mets_indices = list(range(len(mets_features)))\n",
    "mets_split_index = int(0.85 * len(mets_features))\n",
    "\n",
    "mets_train_indices = mets_indices[:mets_split_index]\n",
    "mets_test_indices  = mets_indices[mets_split_index:]\n",
    "\n",
    "mets_x_train = mets_features[mets_train_indices]\n",
    "mets_x_test  = mets_features[mets_test_indices ]\n",
    "mets_y_train = mets_labels[mets_train_indices]\n",
    "mets_y_test  = mets_labels[mets_test_indices ]\n",
    "\n",
    "# verify shapes of training/testing sets\n",
    "print(\"Mets training set shape: \", mets_x_train.shape, mets_y_train.shape)\n",
    "print(\"Mets testing set shape: \" , mets_x_test.shape,  mets_y_test.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5b9288",
   "metadata": {},
   "source": [
    "***MLB***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f671f5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLB features shape:  (1353, 36)\n",
      "MLB labels shape:  (1353,)\n",
      "MLB training set shape:  (1150, 36) (1150,)\n",
      "MLB testing set shape:  (203, 36) (203,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# randomize the order of the rows in the dataframe\n",
    "mlb_data = mlb_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# separate labels from the features\n",
    "mlb_features = mlb_data.drop('did-home-win', axis=1).values\n",
    "mlb_labels = mlb_data['did-home-win'].values\n",
    "\n",
    "# verify shapes features and labels\n",
    "print(\"MLB features shape: \", mlb_features.shape)\n",
    "print(\"MLB labels shape: \", mlb_labels.shape)\n",
    "\n",
    "mlb_indices = list(range(len(mlb_features)))\n",
    "mlb_split_index = int(0.85 * len(mlb_features))\n",
    "\n",
    "mlb_train_indices = mlb_indices[:mlb_split_index]\n",
    "mlb_test_indices  = mlb_indices[mlb_split_index:]\n",
    "\n",
    "mlb_x_train = mlb_features[mlb_train_indices]\n",
    "mlb_x_test  = mlb_features[mlb_test_indices ]\n",
    "mlb_y_train = mlb_labels[mlb_train_indices]\n",
    "mlb_y_test  = mlb_labels[mlb_test_indices ]\n",
    "\n",
    "# verify shapes of training/testing sets\n",
    "print(\"MLB training set shape: \", mlb_x_train.shape, mlb_y_train.shape)\n",
    "print(\"MLB testing set shape: \" , mlb_x_test.shape,  mlb_y_test.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359cd447",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "Using LightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "658103d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# model parameters \n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'accuracy',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fa2bdd",
   "metadata": {},
   "source": [
    "***Mets***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c829a284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a LightGBM Dataset with training features and labels\n",
    "mets_train_data = lgb.Dataset(mets_x_train, label=mets_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a64baf",
   "metadata": {},
   "source": [
    "***MLB***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2dd8def5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a LightGBM Dataset with training features and labels\n",
    "mlb_train_data = lgb.Dataset(mlb_x_train, label=mlb_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5ffb70",
   "metadata": {},
   "source": [
    "## Training the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa4a448",
   "metadata": {},
   "source": [
    "***Mets***\n",
    "\n",
    "#### *Note*\n",
    "Commented out and re-executed to remove large chunks of non-hideable code for when viewing on github.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62e4e57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mets_model = lgb.train(params, mets_train_data, num_boost_round=1000)\n",
    "# mets_model.save_model('models/mets6year.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23293aeb",
   "metadata": {},
   "source": [
    "***MLB***\n",
    "\n",
    "#### *Note*\n",
    "Commented out and re-executed to remove large chunks of non-hideable code for when viewing on github.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f45b3b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlb_model = lgb.train(params, mlb_train_data, num_boost_round=1000)\n",
    "# mlb_model.save_model('models/mlb2023.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee266f1",
   "metadata": {},
   "source": [
    "## Testing the models\n",
    "Here I test the models' accuracy on their own testing sets. This tests each model individually. I.e. the mets model is tested on predicting only mets games (random scatter from 2017-2023) and the mlb model is tested on predicting any mlb game from the 2023 season (up to CUTOFF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12608f81",
   "metadata": {},
   "source": [
    "***Mets***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b73153e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6\n"
     ]
    }
   ],
   "source": [
    "mets_y_pred = mets_model.predict(mets_x_test)\n",
    "mets_y_pred_binary = (mets_y_pred > 0.5).astype(int)\n",
    "accuracy = accuracy_score(mets_y_test, mets_y_pred_binary)\n",
    "\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d36adf",
   "metadata": {},
   "source": [
    "***MLB***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a9ad9d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6699507389162561\n"
     ]
    }
   ],
   "source": [
    "mlb_y_pred = mlb_model.predict(mlb_x_test)\n",
    "mlb_y_pred_binary = (mlb_y_pred > 0.5).astype(int)\n",
    "accuracy = accuracy_score(mlb_y_test, mlb_y_pred_binary)\n",
    "\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ed8dc9",
   "metadata": {},
   "source": [
    "## Predictions!\n",
    "This my first prediction, made on 07/14/2023 (morning), that suggests that the New York Mets will lose to the Los Angeles Dodgers tonight at home. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab93e3e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Los Angeles Dodgers',\n",
       " 0.002204909619759474,\n",
       " {'datetime': '2023-07-14T23:10:00Z',\n",
       "  'date': '2023-07-14',\n",
       "  'away': 'Los Angeles Dodgers',\n",
       "  'home': 'New York Mets',\n",
       "  'home_probable': 'Justin Verlander',\n",
       "  'away_probable': 'Julio Urias',\n",
       "  'venue': 'Citi Field',\n",
       "  'national_broadcasts': ['Apple TV+'],\n",
       "  'series_status': None,\n",
       "  'summary': '2023-07-14 - Los Angeles Dodgers @ New York Mets (Scheduled)'})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data import LeagueStats\n",
    "\n",
    "mlb = LeagueStats()\n",
    "\n",
    "mlb.predict_next_game(\"mlb2023\", \"New York Mets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9588a65f",
   "metadata": {},
   "source": [
    "## Initial Remarks\n",
    "\n",
    "Of the 12 or so predictions that I have made on this first day using the mlb2023 model, I have some observations. The most noticeable of which being that the actual numeric prediction ([0,1]) tends very heavily towards the boundaries (0 and 1). Many of the predictions were well below (0.01) and some of the positive (1) predictions were above 0.98 or so. As I haven't seen any of these games play out yet and evaluated the model on real future data, I can't yet truly comment on this, but it was interesting to note that only 2 of the 12 predictions I made were truly tending towards the center (0.318 and 0.365). \n",
    "\n",
    "The model has also made some bold predictions, betting against the sportsbooks on more than one of these games. Of the 12 game slate for tonight (07/14/2023), the model predicted upsets including... Rockies(+180) over the Yankees(-210), Guardians(+130) over the Rangers(-150), and Nationals(+150) over the Cardinals(-180). The other picks, were either aligned with the betting favorite or were games that didn't have a discernable favorite. As in the Mets game, there isn't a clear betting favorite (note: Urias vs. Verlander), but the model quite confidently believes in the Dodgers to win it. We shall see!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b09a3a",
   "metadata": {},
   "source": [
    "## Hopefully Improved Models & Generalized Data Preparation\n",
    "From here on out, I am going to simplify the data preparation for training into a function so that I can easily mess around and train new models with the goal of surpassing the ~65% testing accuracy that my \"mlb2023\" model is able to achieve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8bfca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd        \n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "def prepare_data(data_dirs, model_name, order=order2 save_dir=None, missing_data_threshold=10):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data_dirs: list of paths to folders with the .xlsx data sheets\n",
    "        save_dir: file_path to save merged .xlsx sheet to if desired\n",
    "            -> must end in .xlsx and be a valid (existing) file path\n",
    "    \n",
    "    Returns:\n",
    "        x_train, x_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    # iterate through mlb data directory to retrieve each file\n",
    "    for dir in data_dirs:\n",
    "        for filename in os.listdir(dir):\n",
    "            if filename.endswith('.xlsx'):\n",
    "                path = os.path.join(dir, filename)\n",
    "                d = pd.read_excel(path)\n",
    "                df = pd.concat([df, d], ignore_index=True)\n",
    "    if save_dir:\n",
    "        df.to_excel(save_dir)\n",
    "    \n",
    "    # remove the game-id, date, home/away team features\n",
    "    df.drop(columns=['game-id', 'date', 'home-team', 'away-team'], inplace=True)\n",
    "    # drops rows with missing labels\n",
    "    df = df.dropna(subset=['did-home-win'])\n",
    "    # convert 'did-home-win' labels to binary values\n",
    "    df['did-home-win'] = df['did-home-win'].astype(int)\n",
    "    \n",
    "    df = df[order]\n",
    "    \n",
    "    df = df.dropna(thresh=df.shape[1] - missing_data_threshold)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    # scale all columns that don't represent averages between 0-1 (i.e. batting avg doesn't need scaling)\n",
    "    columns_to_scale = ['home-starter-season-era', 'away-starter-season-era',\n",
    "                       'home-last10-avg-runs', 'away-last10-avg-runs',\n",
    "                       'home-last10-avg-runs-allowed', 'away-last10-avg-runs-allowed', \n",
    "                       'home-elo-pregame', 'away-elo-pregame',\n",
    "                       'home-pitcher-rgs', 'away-pitcher-rgs',\n",
    "                       'home-last10-avg-hits', 'away-last10-avg-hits',\n",
    "                       'home-last10-avg-hits-allowed', 'away-last10-avg-hits-allowed',\n",
    "                       'home-rating-pregame', 'away-rating-pregame',\n",
    "                       'home-starter-season-runs-per9', 'away-starter-season-runs-per9',\n",
    "                       'home-last10-avg-strikeouts', 'away-last10-avg-strikeouts',\n",
    "                       'home-starter-career-era', 'away-starter-career-era']\n",
    "    # apply min-max normalization to selected features\n",
    "    df[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])\n",
    "    scaler_path = 'models/scalers/'\n",
    "    with open(scaler_path + model_name + '_scaler.pkl', 'wb') as file:\n",
    "        pickle.dump(scaler, file)\n",
    "\n",
    "    # randomize the order of the rows in the dataframe\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    # separate labels from the features\n",
    "    features = df.drop('did-home-win', axis=1).values\n",
    "    labels = df['did-home-win'].values\n",
    "    # verify shapes features and labels\n",
    "    print(\"Features shape: \", df.shape)\n",
    "    print(\"Labels shape: \", df.shape)\n",
    "    indices = list(range(len(features)))\n",
    "    split_index = int(0.85 * len(features))\n",
    "    train_indices = indices[:split_index]\n",
    "    test_indices  = indices[split_index:]\n",
    "    x_train = features[train_indices]\n",
    "    x_test  = features[test_indices ]\n",
    "    y_train = labels[train_indices]\n",
    "    y_test  = labels[test_indices ]\n",
    "    # verify shapes of training/testing sets\n",
    "    print(\"Training set shape: \", x_train.shape, y_train.shape)\n",
    "    print(\"Testing set shape: \" , x_test.shape,  y_test.shape )\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf21fab2",
   "metadata": {},
   "source": [
    "## MLB 3 Year\n",
    "Using the data_retrieval.py script, I collected game data from 2021-2023 seasons in the background and I'm going to pull that data and use it to train a model. The data is from every MLB game during these 3 season (2023 cutoff is 07/09). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a721237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape:  (5975, 37)\n",
      "Labels shape:  (5975, 37)\n",
      "Training set shape:  (5078, 36) (5078,)\n",
      "Testing set shape:  (897, 36) (897,)\n",
      "[LightGBM] [Info] Number of positive: 2709, number of negative: 2369\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8532\n",
      "[LightGBM] [Info] Number of data points in the train set: 5078, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.533478 -> initscore=0.134112\n",
      "[LightGBM] [Info] Start training from score 0.134112\n",
      "Accuracy: 0.6376811594202898\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = ['data/seasons/2021', 'data/seasons/2022', 'data/seasons/2023']\n",
    "x_train, x_test, y_train, y_test = prepare_data(data_dirs=data, model_name=\"mlb3year\", order=order2, missing_data_threshold=10)\n",
    "\n",
    "# model parameters \n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'accuracy',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "}\n",
    "\n",
    "data = lgb.Dataset(x_train, label=y_train)\n",
    "\n",
    "model = lgb.train(params, data, num_boost_round=1000)\n",
    "model.save_model('models/mlb3year.txt')\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f3bc64",
   "metadata": {},
   "source": [
    "## Testing different feature orders\n",
    "In the past 3 models, I've used \"order1\" which creates direct comparisons between adjacent features by placing a home team's statistic directly next to the away team's same stat. Here I will try a different order, primarily the order where I place all of one team's statistics first and then the other team's after. Below I will use the same data as ***mlb3year***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b5c43f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape:  (5975, 37)\n",
      "Labels shape:  (5975, 37)\n",
      "Training set shape:  (5078, 36) (5078,)\n",
      "Testing set shape:  (897, 36) (897,)\n",
      "[LightGBM] [Info] Number of positive: 2727, number of negative: 2351\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000804 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8551\n",
      "[LightGBM] [Info] Number of data points in the train set: 5078, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537022 -> initscore=0.148361\n",
      "[LightGBM] [Info] Start training from score 0.148361\n",
      "Accuracy: 0.6432552954292085\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = ['data/seasons/2021', 'data/seasons/2022', 'data/seasons/2023']\n",
    "x_train, x_test, y_train, y_test = prepare_data(data_dirs=data, model_name=\"mlb3year_test\", order=order2, missing_data_threshold=10)\n",
    "\n",
    "# model parameters \n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'accuracy',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "}\n",
    "\n",
    "data = lgb.Dataset(x_train, label=y_train)\n",
    "\n",
    "model = lgb.train(params, data, num_boost_round=1000)\n",
    "model.save_model('models/mlb3year_test.txt')\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608b829b",
   "metadata": {},
   "source": [
    "### Remarks\n",
    "After training the model a couple times with \"order2\", it appears that the order doesn't make a significant impact on the model's testing accuracy. If anything, however, I've noticed that the training accuracies were on average a little bit higher. Moving forward, I will use order2 as the default feature order. \n",
    "\n",
    "Additionally, I will retrain the official mlb3year model with order2, so that the saved model is up to date.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
